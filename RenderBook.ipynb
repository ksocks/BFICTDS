{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFICTDS: Baby's First Image Classification Training Data Set\n",
    "\n",
    "An opensource book.\n",
    "\n",
    "This noteboook downloads images from the Open Images dataset and arranges them into the pages of the BFICTDS book, output in the form of a pdf. The title and image classes are easily customizable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Download images from Open Images dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download/load OID images and class lists\n",
    "\n",
    "We are using the human image labels with the full image-level label class list (rather than the reduced class list for the box-labeled set) -- download information obtained here https://storage.googleapis.com/openimages/web/download.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OID v6\n",
    "OID_data_path = \"OID_data_v6/\"\n",
    "if (not os.path.exists(OID_data_path)):\n",
    "    os.makedirs(OID_data_path)\n",
    "    \n",
    "label_csv_path = OID_data_path+\"oidv6-train-annotations-human-imagelabels.csv\"\n",
    "remote_label_csv_path = \"https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-human-imagelabels.csv\"\n",
    "label_names_csv_path = OID_data_path+\"oidv6-class-descriptions.csv\"\n",
    "remote_label_names_csv_path = \"https://storage.googleapis.com/openimages/v6/oidv6-class-descriptions.csv\"\n",
    "\n",
    "if not os.path.exists(label_csv_path):\n",
    "    ! wget \"$remote_label_csv_path\" -O \"$label_csv_path\"\n",
    "if not os.path.exists(label_names_csv_path):\n",
    "    ! wget \"$remote_label_names_csv_path\" -O \"$label_names_csv_path\"\n",
    "    \n",
    "# load the label data from disk into Pandas DataFrames -- can take a minute due to large file size\n",
    "label_df_v6 = pd.read_csv(label_csv_path)\n",
    "label_names_df_v6 = pd.read_csv(label_names_csv_path,names=['key','name'],index_col=1) # this maps human-readable label names to their key value\n",
    "\n",
    "\n",
    "        \n",
    "display(label_df_v6)\n",
    "display(label_names_df_v6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select image classes\n",
    "Image classes can be picked out from the list above. They can also be found online using the Open Image dataset explorer.\n",
    "Here's a useful code snippet to find classes starting with a given letter in case you want to do an A-Z thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all image classes that start with a letter, e.g for the letter X:\n",
    "label_names_df_v6[label_names_df_v6.index.str.startswith('X')]\n",
    "# ... none of these turn out to be very good classes for a children's book :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the list of classes we will download images for:\n",
    "classes = ['Apple', \n",
    "           'Bird', \n",
    "           'Cat', \n",
    "           'Dog',\n",
    "           'Elephant',\n",
    "           'Fish',\n",
    "           'Giraffe',\n",
    "           'Helicopter',\n",
    "           'Ice cream',\n",
    "           'Jellyfish',\n",
    "           'Kangaroo',\n",
    "           'Lemon',\n",
    "           'Motorcycle',\n",
    "           'Noodle',\n",
    "           'Orange',\n",
    "           'Pear',\n",
    "           'Quilt',\n",
    "           'Reptile',\n",
    "           'Snowplow',\n",
    "           'Train',\n",
    "           'Umbrella',\n",
    "           'Vegetable',\n",
    "           'Waffle',\n",
    "           # no suitable X classes in dataset :(\n",
    "           'Yak',\n",
    "           'Zebra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images examples in selected classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to obtain images from s3 based on their human-readable class name\n",
    "def get_images_v6(label_name,limit=-1,base_path=OID_data_path):\n",
    "    # limit = number of images to download (-1 for all available)\n",
    "    \n",
    "    s3_path = \"s3://open-images-dataset/train/\"\n",
    "    \n",
    "    label_key = label_names_df_v6.loc[label_name,'key']\n",
    "    image_names = label_df_v6.query(\"LabelName==@label_key and Confidence==1\")['ImageID'][:limit]\n",
    "    print(image_names)\n",
    "    \n",
    "    if (not os.path.exists(base_path + label_name)):\n",
    "        os.makedirs(base_path + label_name)\n",
    "        \n",
    "    for img in image_names:\n",
    "        file_name = img+\".jpg\"\n",
    "        ! aws s3 --no-sign-request cp \"$s3_path$file_name\" \"$base_path$label_name/\"\n",
    "\n",
    "# Download up to 100 examples in each image class\n",
    "for c in classes:\n",
    "    get_images_v6(c,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Curate Images (by hand)\n",
    "\n",
    "The images downloaded in the previous step are stored in the OID_data_v6/<classname> folders.\n",
    "It's useful to go through them by hand to remove misclassified images, images featuring people, drawings/advertisements, images featuring another object class. The rest of the notebook works with the images downloaded to the folder, so you can simply delete any you want to remove. I recommend copying all the images into a \"curated_images\" folder and then going through them using your file manager.\n",
    "\n",
    "It'd be a fun improvement to this project to check the other image-labels by hand (for competing object classes, etc. ) and do some automatic filtering. You could also use the bounding-box dataset to crop images to specific objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate pages and print-ready PDF\n",
    "\n",
    "Each page type is rendered by a separate function.\n",
    "We use combine these with the pdfpages library to render a complete pdf of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### page rendering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front Cover\n",
    "def render_cover(\n",
    "    im_path,\n",
    "    size=15,\n",
    "    figsize=(8.5,8.5),\n",
    "    dpi = 300,\n",
    "    font=\"Monospace\",\n",
    "    title=\"Baby's First\\nImage Classification\\nTraining Data Set\",\n",
    "    subtitle=\"an opensource book\\nhttps://github.com/ksocks/BFICTDS\\nillustrated by the open images dataset\"\n",
    "    ):\n",
    "    # render the front cover\n",
    "    # size is the dimension of the image grid, e.g. size=15 is 15*15 grid\n",
    "\n",
    "    im_files = np.random.choice(glob.glob(im_path+\"*/*.jpg\"),size*size,replace=False)\n",
    "    fig, ax = plt.subplots(size,size, figsize=figsize, dpi=dpi)\n",
    "    fig.patch.set_facecolor('black')\n",
    "\n",
    "    ind = 0\n",
    "    for f in im_files[:size**2]:\n",
    "        ax[ind%size, int(ind/size)].set_axis_off()\n",
    "        im = Image.open(f)\n",
    "        enhancer = ImageEnhance.Brightness(im)\n",
    "        ax[ind%size, int(ind/size)].imshow(enhancer.enhance(0.4))\n",
    "        ind += 1\n",
    "     \n",
    "    fig.text(0.5,0.5,title.upper(),size=50,fontname=font,color='white',horizontalalignment='center',verticalalignment='center',weight='bold')\n",
    "    fig.text(0.5,0.1,subtitle,size=20,fontname=font,color='white',horizontalalignment='center',verticalalignment='center',weight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# render lowres sample page:\n",
    "render_cover(im_path=OID_data_path,dpi=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back Cover\n",
    "def render_back_cover(\n",
    "    im_path,\n",
    "    size=15,\n",
    "    figsize=(8.5,8.5),\n",
    "    dpi = 300,\n",
    "    ):\n",
    "    # render the front cover\n",
    "    # size is the dimension of the image grid, e.g. size=15 is 15*15 grid\n",
    "    \n",
    "    im_files = np.random.choice(glob.glob(im_path+\"*/*.jpg\"),size*size,replace=False)\n",
    "    fig, ax = plt.subplots(size,size, figsize=figsize, dpi=dpi)\n",
    "    #fig.patch.set_facecolor('black')\n",
    "\n",
    "    ind = 0\n",
    "    for f in im_files[:size**2]:\n",
    "        ax[ind%size, int(ind/size)].set_axis_off()\n",
    "        im = Image.open(f)\n",
    "        ax[ind%size, int(ind/size)].imshow(im)\n",
    "        ind += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "# render lowres sample page:\n",
    "render_back_cover(im_path=OID_data_path,dpi=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front Matter\n",
    "def render_front_matter(\n",
    "     figsize=(8.5,8.5),\n",
    "     dpi=300\n",
    "     ):\n",
    "    # ---------\n",
    "    # Front Matter\n",
    "    # ---------\n",
    "\n",
    "    copyright_text=\"\"\"\n",
    "    This work is licensed under a creative commons \n",
    "    Attribution-NonCommercial-ShareAlike 4.0 International license (CC BY-NC-SA 4.0),\n",
    "    which can be found here https://creativecommons.org/licenses/by-nc-sa/4.0/\n",
    "\n",
    "    First date of publication, August 2020.\n",
    "    \n",
    "    ISBN: 978-1-71666-838-8\n",
    "    Imprint: Lulu.com\n",
    "\n",
    "    This is an open source book. The contents and code to \n",
    "    generate or modify the book are available on github:\n",
    "    https://github.com/ksocks/BFICTDS\n",
    "\n",
    "    The images reproduced in this work were obtained from the Open Images Dataset v6\n",
    "    https://storage.googleapis.com/openimages/web/index.html\n",
    "    The individual images are available under a creative commons license,\n",
    "    and specific attribution data can be found on this book's github page.\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=figsize,dpi=dpi,facecolor='white')\n",
    "    plt.text(0.1,0.6, copyright_text,fontname='arial',size=8,color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    fig.gca().spines[\"top\"].set_visible(False)\n",
    "    fig.gca().spines[\"left\"].set_visible(False)\n",
    "    fig.gca().spines[\"bottom\"].set_visible(False)\n",
    "    fig.gca().spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "# render lowres sample page:\n",
    "render_front_matter(dpi=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction\n",
    "def render_intro(\n",
    "     figsize=(8.5,8.5),\n",
    "     dpi=300,\n",
    "     font=\"Monospace\"\n",
    "     ):\n",
    "    \n",
    "    # ---------\n",
    "    # Intro\n",
    "    # ---------\n",
    "    \n",
    "    poem_text=\"\"\"\n",
    "    > Dear little neural net,\n",
    "    > \n",
    "    > You are making sense of a world of sights and sounds,\n",
    "    > Where your labels are not always certain,\n",
    "    > And your examples sometimes confound.\n",
    "    > \n",
    "    > But, you are a little miracle\n",
    "    > With the power to represent anything you wish\n",
    "    > And with some parental supervision \n",
    "    > And a push or two from a teacher \n",
    "    > Through the flat gradients\n",
    "    > And local minima of life\n",
    "    > Your vision will become clear.\n",
    "    > \n",
    "    > Yours truly,\n",
    "    >\n",
    "    > A neural net with a few more \n",
    "    > training epochs under its belt\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize,dpi=dpi,facecolor='white')\n",
    "    plt.text(0.1,0.3, poem_text,fontname=font,size=12,color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    fig.gca().spines[\"top\"].set_visible(False)\n",
    "    fig.gca().spines[\"left\"].set_visible(False)\n",
    "    fig.gca().spines[\"bottom\"].set_visible(False)\n",
    "    fig.gca().spines[\"right\"].set_visible(False)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# render lowres sample page:\n",
    "render_intro(dpi=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body pages for each image class\n",
    "def render_body_page(\n",
    "    im_path,\n",
    "    im_class,\n",
    "    figsize=(8.5,8.5),\n",
    "    dpi=300,\n",
    "    font=\"Monospace\"):\n",
    "    \n",
    "    im_files = glob.glob(im_path+im_class+\"/*.jpg\")\n",
    "    len(im_files)\n",
    "\n",
    "    # this creates a simple adaptive grid size depending on the number of available images:\n",
    "    if (len(im_files)>=9):\n",
    "        size = 3\n",
    "    else:\n",
    "        print(\"not enough images in class {}\".format(im_class))\n",
    "        return\n",
    "    if (len(im_files)>=16):\n",
    "        size = 4\n",
    "    if (len(im_files)>=25):# up to 5x5 grid depending on number of successfully downloaded images\n",
    "        size = 5\n",
    "\n",
    "    fig, ax = plt.subplots(size,size, figsize=figsize, dpi=dpi)\n",
    "\n",
    "    ind = 0\n",
    "    for f in im_files[:size**2]:\n",
    "        ax[ind%size, int(ind/size)].set_axis_off()\n",
    "        ax[ind%size, int(ind/size)].imshow(Image.open(f))\n",
    "        ind += 1\n",
    "\n",
    "    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.85, wspace=0.1, hspace=0.1)\n",
    "    fig.text(0.5,0.97,\" \") #whitespace margin hack\n",
    "    fig.text(0.5,0.03,\" \") #whitespace margin hack\n",
    "\n",
    "    fig.text(0.5,0.87,im_class.upper(),size=40,fontname=font,weight='bold',verticalalignment='bottom',horizontalalignment='center')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# render lowres sample pages:\n",
    "render_body_page(im_path=OID_data_path,im_class=\"Apple\",dpi=50);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the complete book to a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output options\n",
    "\n",
    "font = \"Monospace\" # main book font\n",
    "figsize = (8.5,8.5) # <-- 8.5 in x 8.5 in is optimized for publishing on LULU, and the pages have been tweaked to fit this.\n",
    "dpi = 300\n",
    "\n",
    "im_path = \"curated_images/\" # where to look for image class subfolders, change if you copy them to a different directory after using the downloader\n",
    "\n",
    "# render book.pdf\n",
    "with PdfPages('book.pdf') as pdf:\n",
    "    \n",
    "    # ----------------\n",
    "    # Cover\n",
    "    # ----------------\n",
    "    fig = render_cover(im_path=im_path,figsize=figsize,dpi=dpi,font=font)\n",
    "    pdf.savefig(fig,facecolor=fig.get_facecolor())  # saves the current figure into a pdf page\n",
    "    plt.close()\n",
    "    \n",
    "    # ---------\n",
    "    # Front Matter\n",
    "    # ---------\n",
    "\n",
    "    fig = render_front_matter(figsize=figsize,dpi=dpi)\n",
    "    pdf.savefig(fig,facecolor=fig.get_facecolor())  # saves the current figure into a pdf page\n",
    "    plt.close()\n",
    "    \n",
    "    # ---------\n",
    "    # Intro\n",
    "    # ---------\n",
    "    \n",
    "    fig = render_intro(figsize=figsize,dpi=dpi,font=font)\n",
    "    pdf.savefig(fig,facecolor=fig.get_facecolor())  # saves the current figure into a pdf page\n",
    "    plt.close()\n",
    " \n",
    "    \n",
    "    # ---------\n",
    "    # Book body\n",
    "    # ---------\n",
    "    \n",
    "    for c in classes[:]:\n",
    "        fig = render_body_page(im_path=im_path,im_class=c,figsize=figsize,dpi=dpi,font=font)\n",
    "        pdf.savefig(fig,facecolor=fig.get_facecolor())  # saves the current figure into a pdf page\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "    # ----------------\n",
    "    # Back Cover\n",
    "    # ----------------\n",
    "    fig = render_back_cover(im_path=im_path,figsize=figsize,dpi=dpi)\n",
    "    pdf.savefig(fig,facecolor=fig.get_facecolor())  # saves the current figure into a pdf page\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) (optional) Prepare cover files for Lulu.com (by hand)\n",
    "\n",
    "Lulu requires the front and back covers to be provided in a separate file with a given template format. You can use the provided \"lulu covers.svg\" and the pdf import capabilities of the [Inkscape editor](https://inkscape.org/) for example to paste in your new cover images if you want to change them, then re-generate a pdf to use on Lulu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) (optional) Obtain attribution information for selected images\n",
    "\n",
    "Note this step involves downloading the complete label information, which is a quite large file (2.3GB), to get attribution information for the individual images selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the csv with attribution info \n",
    "attribution_csv_path = OID_data_path + \"oidv6-train-images-with-labels-with-rotation.csv\"\n",
    "remote_attribution_csv_path = \"https://storage.googleapis.com/openimages/v6/oidv6-train-images-with-labels-with-rotation.csv\"\n",
    "\n",
    "if not os.path.exists(attribution_csv_path):\n",
    "    ! wget \"$remote_attribution_csv_path\" -O \"$attribution_csv_path\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of images used in the book\n",
    "# note this actually includes some images that aren't rendered onto the pages, since we ignored the grid size logic\n",
    "\n",
    "imgs_used = []\n",
    "im_path = \"curated_images/\"\n",
    "imgs=glob.glob(im_path+\"*/*.jpg\")\n",
    "for i in imgs:\n",
    "    imgs_used.append(i.split(\"/\")[2].split(\".\")[0])\n",
    "print(imgs_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get csv column headers\n",
    "with open(attribution_csv_path,\"r\",newline='') as f:\n",
    "    r = csv.reader(f)\n",
    "    # print header\n",
    "    print(next(r))\n",
    "    print(next(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attribution info by brute force scanning file - takes about 15 minutes to go through the ~7 million entries\n",
    "attribution = dict()\n",
    "with open(attribution_csv_path,\"r\",newline='') as f:\n",
    "    r = csv.reader(f)\n",
    "    n = 0\n",
    "    for row in r:\n",
    "        if row[0] in imgs_used:\n",
    "            attribution[row[0]]=[row[2],row[4],row[6],row[7]]\n",
    "        print(\"scanning row {}\".format(n),end='\\r')\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print attribution info and dump to file\n",
    "\n",
    "print(attribution)\n",
    "with open('attribution.json', 'w') as file:\n",
    "     file.write(json.dumps(attribution))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
